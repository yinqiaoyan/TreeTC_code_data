{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Download the CIFAR-100 data and preprocess\n",
    "\n",
    "**Output of this step:**\n",
    "\n",
    "* testData: Input data of the TreeTC model (\"rawData.csv\")\n",
    "* indices: Corresponding index of each image in the raw data\n",
    "\n",
    "**Remark:**\n",
    "\n",
    "* tensorflow==1.14.0\n",
    "* keras==2.3.1\n",
    "\n",
    "**Note:**\n",
    "\n",
    "* Choose the working directory as the directory where this code file locates.\n",
    "* Please first install the required R and Python packages:\n",
    "    * R: System_preparation.R\n",
    "    * Python: pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 1.14.0\n",
      "keras version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "print(\"tensorflow version:\", tensorflow.__version__)\n",
    "print(\"keras version:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar100.load_data(label_mode=\"fine\") # label: \"fine\"  / \"coarse\"\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization of cifar100 original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(50000, 3072) / 255  \n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select 9 classes\n",
    "\n",
    "Superclasses information:\n",
    "\n",
    "| Superclass                     | Class                                               |\n",
    "| :----------------------------- | :----------------------------------------------------------- |\n",
    "| aquatic mammals                | 30 dolphin                                           |\n",
    "| fish                           | 67 flatfish, 73 sharks                             |\n",
    "| fruit and vegetables           | 53 oranges    |\n",
    "| household furniture            | 20 chair                                             |\n",
    "| large carnivores               | 43 lion                                              |\n",
    "| large omnivores and herbivores | 21 chimpanzee                   |\n",
    "| trees                          | 47 maple, 52 oak                              |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_select = [20, 21, 30, 43, 47, 52, 53, 67,  73]\n",
    "labels_bool = list(map(lambda x: x in labels_select, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 3072)\n",
      "(4500, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_sub9 = X_train[labels_bool]\n",
    "y_train_sub9 = y_train[labels_bool]\n",
    "\n",
    "print(X_train_sub9.shape)\n",
    "print(y_train_sub9.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAP: dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "n_components = 10\n",
    "reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=n_components, metric='euclidean', random_state=42)\n",
    "\n",
    "X_train_sub9_umap10D = reducer.fit_transform(X_train_sub9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign 4500 images to 30 sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_umap = X_train_sub9_umap10D\n",
    "\n",
    "numOfSubjects = 30         # number of sources\n",
    "numOfClasses = 3           # number of image classes for one source\n",
    "m = 50                     # number of data in one image class for one source\n",
    "numOfData_eachClass = 500  # total number of images in one image class\n",
    "\n",
    "indicesMat = np.zeros((len(labels_select), numOfData_eachClass+1))\n",
    "for i in range(len(labels_select)):\n",
    "    indicesMat[i, np.arange(numOfData_eachClass)] = np.where(y_train_sub9 == labels_select[i])[0]\n",
    "\n",
    "indicesMat = indicesMat.astype(\"int\")\n",
    "DataOrigin = [0] * numOfSubjects\n",
    "indices = []\n",
    "\n",
    "y1 = [20, 21, 30]\n",
    "y2 = [43, 47, 52]\n",
    "y3 = [53, 67, 73]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in range(numOfSubjects):\n",
    "    if s % 3 == 0:\n",
    "        classIds = y1\n",
    "    elif s % 3 == 1:\n",
    "        classIds = y2\n",
    "    else:\n",
    "        classIds = y3\n",
    "    \n",
    "    tmpMat = np.zeros((numOfClasses * m, X_umap.shape[1]))\n",
    "    num = 0\n",
    "\n",
    "    for tmp in classIds:\n",
    "        ind = np.where([l == tmp for l in labels_select])[0]\n",
    "        k = indicesMat[ind, numOfData_eachClass]\n",
    "        selIds = indicesMat[ind, int(k):(int(k)+m)]  # only integer scalar arrays can be converted to a scalar index!\n",
    "                                                     # selIds: (1, 50)\n",
    "        tmpMat[num:(num+m), :] = X_umap[selIds, :]\n",
    "        indicesMat[ind, numOfData_eachClass] = k + m\n",
    "        num = num + m\n",
    "        indices.extend(np.squeeze(selIds))           # np.squeeze: (50,)\n",
    "\n",
    "    DataOrigin[s] = tmpMat\n",
    "    \n",
    "# Attention: indices here in Python equals indices - 1 in R !!!\n",
    "# If we use indices in Python, when we draw the images, we DO NOT need to conduct \"clIds = TopClIds[cl, :] - 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = np.vstack(DataOrigin)\n",
    "rawData = np.hstack((testData, np.array(indices).reshape(-1,1)))\n",
    "np.savetxt(\"./rawData.csv\", rawData, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step2. Implement TreeTC and conduct MCMC\n",
    "\n",
    "Conduct in \"Step2_TreeTC_mcmc.R\"\n",
    "\n",
    "\n",
    "# Step 3. Draw Figure S9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import os, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yyq/opt/anaconda3/envs/tf_36/lib/python3.6/site-packages/ipykernel_launcher.py:23: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n"
     ]
    }
   ],
   "source": [
    "X = X_train_sub9\n",
    "y = y_train_sub9\n",
    "X_reshape = (X * 255).reshape(X.shape[0], 32, 32, 3).astype(np.int)\n",
    "\n",
    "for group_id in [1,2,3]:    \n",
    "    TopClIds = pd.read_csv('./TopClIds/group' + str(group_id) + '.csv', header = None)\n",
    "    TopClIds = np.array(TopClIds)\n",
    "    \n",
    "    ncol = 2\n",
    "    nrow = 5\n",
    "    \n",
    "    for cl in range(TopClIds.shape[0]):\n",
    "        clIds = TopClIds[cl, :]\n",
    "        imgNames = list(map(lambda i: \"./image_group\" + str(group_id) + \"/\" + \"img\" + str(i) + \".png\", np.arange(len(clIds))))\n",
    "        for i in range(len(clIds)):\n",
    "            clId = clIds[i]\n",
    "            pyplot.imsave(imgNames[i], X_reshape[clId:(clId+1)][0].astype(np.uint8))\n",
    "\n",
    "        imgs = [ PIL.Image.open(i) for i in imgNames ]\n",
    "        imgs_all = [0] * nrow\n",
    "        iii = [i * ncol for i in range(nrow+1)]\n",
    "        for j in range(nrow):\n",
    "            imgs_all[j] = np.hstack( (np.asarray( k ) for k in imgs[iii[j]:iii[j+1]] ) )\n",
    "\n",
    "        imgs_comb = np.vstack(imgs_all)\n",
    "        imgs_comb = PIL.Image.fromarray( imgs_comb)\n",
    "        imgs_comb.save(\"./image_group\" + str(group_id) + \"/\" + \"10Imgs-\" + str(cl) + \".png\" )\n",
    "        \n",
    "    delDir = \"./image_group\" + str(group_id)\n",
    "    delList = os.listdir(delDir)\n",
    "    for f in delList:\n",
    "        filePath = os.path.join( delDir, f )\n",
    "        if re.match(\"img\\d.png\", f):\n",
    "            os.remove(filePath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_36",
   "language": "python",
   "name": "tf_36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
